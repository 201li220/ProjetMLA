# MLAProject: Parameter-Efficient Transfer Learning for NLP

## Description
This project aims to reproduce the results presented in the paper titled "Parameter-Efficient Transfer Learning for NLP": 
http://proceedings.mlr.press/v97/houlsby19a.html
The primary objective is to implement the proposed methods and assess their effectiveness in the context of natural language processing (NLP).

The paper introduces parameter-efficient transfer learning techniques for NLP tasks. It explores methods to leverage pre-trained language models effectively while minimizing the number of parameters. For detailed insights, please refer to the original paper.

## Project Structure
The project is organized into individual modules created by each participant. The final implementation, modules, and a demonstration notebook can be found in the "main" directory.

## Installation
To set up the project, use the provided requirements.txt file. Install the required dependencies using the following command:

pip install -r requirements.txt

## Usage
For detailed usage instructions, please refer to the "main" file on the GitHub repository. This file contains comprehensive documentation and examples to guide users through the project.

## Contributors

- LAZIAMOND Ugo (Ugo06)
- PEROSINO Cyril (CaZino58)
- HOUDRE Nicolas (201li220)
- YU Jihan (Eter7Heaven)
